name: Metro Data Pipeline

on:
  # 푸시 시 실행 (테스트용 - 즉시 실행 확인)
  push:
    branches: [main]
    paths:
      - 'src/**'
      - '.github/workflows/**'

  schedule:
    - cron: '*/5 * * * *'

  # 수동 실행
  workflow_dispatch:
    inputs:
      stations:
        description: '수집할 역 (쉼표 구분)'
        required: false
        default: '서울,강남,홍대입구'

env:
  PYTHON_VERSION: '3.11'
  DATA_DIR: data

jobs:
  # ===== 데이터 수집 =====
  collect:
    runs-on: ubuntu-latest
    outputs:
      collected_files: ${{ steps.collect.outputs.files }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: pip install requests python-dotenv

      - name: Collect metro data
        id: collect
        env:
          SEOUL_API_KEY: ${{ secrets.SEOUL_API_KEY }}
          STATIONS: ${{ github.event.inputs.stations || '서울,강남,홍대입구' }}
          DATA_DIR: ${{ env.DATA_DIR }}
        run: |
          python -m src.collector
          echo "files=$(ls ${{ env.DATA_DIR }}/raw/*.json 2>/dev/null | wc -l)" >> $GITHUB_OUTPUT

      - name: Upload raw data
        uses: actions/upload-artifact@v4
        with:
          name: raw-data
          path: ${{ env.DATA_DIR }}/raw/

  # ===== 데이터 처리 =====
  process:
    runs-on: ubuntu-latest
    needs: collect

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: pip install pandas

      - name: Download raw data
        uses: actions/download-artifact@v4
        with:
          name: raw-data
          path: ${{ env.DATA_DIR }}/raw/

      - name: Process data
        env:
          DATA_DIR: ${{ env.DATA_DIR }}
        run: python -m src.processor

      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: ${{ env.DATA_DIR }}/processed/

  # ===== S3 업로드 (선택적 - Phase 6에서 활성화) =====
  # upload:
  #   runs-on: ubuntu-latest
  #   needs: process
  #   if: github.event_name == 'schedule'  # 스케줄 실행시에만

  #   steps:
  #     - name: Download processed data
  #       uses: actions/download-artifact@v4
  #       with:
  #         name: processed-data
  #         path: ${{ env.DATA_DIR }}/processed/

  #     - name: Configure AWS credentials
  #       uses: aws-actions/configure-aws-credentials@v4
  #       with:
  #         aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  #         aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #         aws-region: ap-northeast-2

  #     - name: Upload to S3
  #       run: |
  #         DATE=$(date +%Y/%m/%d/%H)
  #         aws s3 sync ${{ env.DATA_DIR }}/processed/ \
  #           s3://${{ secrets.S3_BUCKET }}/metro/processed/$DATE/

  # ===== 알림 =====
  notify:
    runs-on: ubuntu-latest
    needs: [collect, process]
    if: always()  # 성공/실패 관계없이 실행

    steps:
      - name: Send notification
        run: |
          if [ "${{ needs.process.result }}" == "success" ]; then
            echo "✅ 파이프라인 성공"
          else
            echo "❌ 파이프라인 실패"
          fi